# 6 Reviews & Static Code Analysis Tools

## 6.1 Conduct a Review

### Introduction

We conducted a peer review of Group 2's [repository](https://github.com/Ricardo0919/studyconnect-software-testing). We used the provided review template. The completed review table can be found [here](./files/review_english.xlsx).

### Review Roles

Due to the scope and formality of the review, we determined that a moderator was not required.

Our team met on November 21, 2025, at approximately 10:30 to review Group 2's code.
In the first phase, each team member reviewed a portion of the code in the role of an expert. We then presented our observations to one another and discussed whether to include them in our findings.

Erik recorded our findings in the template file.


## 6.2 Retrospective – Reflection on the Review

### **What we noticed**
During the review, we quickly realized that the process did not help us as much as expected. The main difficulty was reviewing code written in programming languages or frameworks we were unfamiliar with. Because we did not fully understand parts of the codebase, identifying real defects versus intended design choices became extremely time-consuming and often uncertain. Instead of spotting meaningful issues, we spent most of the time trying to interpret basic structures, which reduced the effectiveness of the review.

Another major challenge was the planning phase. Since we had no prior experience with the provided review templates, understanding the master plan and the review structure took longer than the actual review itself. We had to spend additional time figuring out how to apply the process correctly before we could even begin evaluating the other group’s work.

### **Effectiveness of the review method**
For our team, the chosen review approach did not prove effective. The combination of unfamiliar code, unclear expectations, and a strict template-driven process created more overhead than value. The list of findings also led to long internal discussions—especially about how to prioritize issues. Without being able to communicate directly with the other group, it was difficult to judge whether certain aspects were intentional design decisions or actual mistakes.

Because of this, the review felt more like guesswork than a structured quality assurance activity.

### **Suitability for our team**
Given our limited experience with code reviews and the lack of shared technological background with the reviewed team, reviews in this format are not very suitable for us at this stage. They may be more helpful in the future when:

- the codebase uses languages or frameworks we understand,
- we have more experience with review templates and processes, and
- communication with the authors is possible to clarify uncertainties.

### **Conclusion**
Overall, the review did not provide the expected benefits. It was time-consuming, difficult to execute, and did not lead to clear or confident findings. For our team, this type of formal review process is only useful when the reviewed material is familiar, the process is well understood, and communication between teams is possible.
